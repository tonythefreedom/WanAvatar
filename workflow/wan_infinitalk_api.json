{
  "232": {
    "class_type": "SetNode",
    "inputs": {
      "IMAGE": [
        "97",
        0
      ]
    }
  },
  "97": {
    "class_type": "LoadImage",
    "inputs": {
      "image": "bcfc901f04d08288225514481ffa7a2fda5b36d160e8273f3894cf1e6a112d03.jpg",
      "upload": "image"
    }
  },
  "226": {
    "class_type": "SetNode",
    "inputs": {
      "AUDIO": [
        "224",
        0
      ]
    }
  },
  "229": {
    "class_type": "SetNode",
    "inputs": {
      "INT": [
        "206",
        0
      ]
    }
  },
  "231": {
    "class_type": "SetNode",
    "inputs": {
      "STRING": [
        "215",
        0
      ]
    }
  },
  "227": {
    "class_type": "GetNode",
    "inputs": {}
  },
  "101": {
    "class_type": "LoraLoaderModelOnly",
    "inputs": {
      "model": [
        "95",
        0
      ],
      "lora_name": "wan2.2_i2v_A14b_high_noise_lora_rank64_lightx2v_4step_1022.safetensors",
      "strength_model": 1
    }
  },
  "112": {
    "class_type": "PathchSageAttentionKJ",
    "inputs": {
      "model": [
        "101",
        0
      ],
      "sage_attention": "auto",
      "allow_compile": false
    }
  },
  "104": {
    "class_type": "ModelSamplingSD3",
    "inputs": {
      "model": [
        "112",
        0
      ],
      "shift": 5
    }
  },
  "102": {
    "class_type": "LoraLoaderModelOnly",
    "inputs": {
      "model": [
        "96",
        0
      ],
      "lora_name": "lightx2v_I2V_14B_480p_cfg_step_distill_rank128_bf16.safetensors",
      "strength_model": 1.0000000000000002
    }
  },
  "111": {
    "class_type": "PathchSageAttentionKJ",
    "inputs": {
      "model": [
        "102",
        0
      ],
      "sage_attention": "auto",
      "allow_compile": false
    }
  },
  "103": {
    "class_type": "ModelSamplingSD3",
    "inputs": {
      "model": [
        "111",
        0
      ],
      "shift": 5.000000000000001
    }
  },
  "234": {
    "class_type": "SetNode",
    "inputs": {
      "MODEL": [
        "103",
        0
      ]
    }
  },
  "233": {
    "class_type": "SetNode",
    "inputs": {
      "MODEL": [
        "104",
        0
      ]
    }
  },
  "249": {
    "class_type": "GetNode",
    "inputs": {}
  },
  "241": {
    "class_type": "GetNode",
    "inputs": {}
  },
  "240": {
    "class_type": "GetNode",
    "inputs": {}
  },
  "236": {
    "class_type": "GetNode",
    "inputs": {}
  },
  "251": {
    "class_type": "GetNode",
    "inputs": {}
  },
  "247": {
    "class_type": "SetNode",
    "inputs": {
      "VAE": [
        "90",
        0
      ]
    }
  },
  "248": {
    "class_type": "SetNode",
    "inputs": {
      "MODEL_PATCH": [
        "171",
        0
      ]
    }
  },
  "171": {
    "class_type": "ModelPatchLoader",
    "inputs": {
      "name": "Wan2_1-InfiniTetalk-Single_fp16.safetensors"
    }
  },
  "250": {
    "class_type": "SetNode",
    "inputs": {
      "CLIP": [
        "84",
        0
      ]
    }
  },
  "84": {
    "class_type": "CLIPLoader",
    "inputs": {
      "clip_name": "umt5_xxl_fp8_e4m3fn_scaled.safetensors",
      "type": "wan",
      "device": "default"
    }
  },
  "256": {
    "class_type": "GetNode",
    "inputs": {}
  },
  "254": {
    "class_type": "GetNode",
    "inputs": {}
  },
  "257": {
    "class_type": "GetNode",
    "inputs": {}
  },
  "204": {
    "class_type": "GetImageSizeAndCount",
    "inputs": {
      "image": [
        "147",
        0
      ]
    }
  },
  "188": {
    "class_type": "ImageFromBatch",
    "inputs": {
      "image": [
        "147",
        0
      ],
      "length": [
        "205",
        0
      ],
      "batch_index": 4
    }
  },
  "242": {
    "class_type": "GetNode",
    "inputs": {}
  },
  "235": {
    "class_type": "SetNode",
    "inputs": {
      "IMAGE": [
        "189",
        0
      ]
    }
  },
  "238": {
    "class_type": "GetNode",
    "inputs": {}
  },
  "237": {
    "class_type": "GetNode",
    "inputs": {}
  },
  "252": {
    "class_type": "SetNode",
    "inputs": {
      "INT": [
        "195",
        3
      ]
    }
  },
  "253": {
    "class_type": "SetNode",
    "inputs": {
      "INT": [
        "195",
        4
      ]
    }
  },
  "258": {
    "class_type": "SetNode",
    "inputs": {
      "IMAGE": [
        "195",
        0
      ]
    }
  },
  "255": {
    "class_type": "GetNode",
    "inputs": {}
  },
  "259": {
    "class_type": "GetNode",
    "inputs": {}
  },
  "192": {
    "class_type": "PainterAI2V",
    "inputs": {
      "model_high_noise": [
        "240",
        0
      ],
      "model_low_noise": [
        "241",
        0
      ],
      "model_patch": [
        "249",
        0
      ],
      "positive": [
        "93",
        0
      ],
      "negative": [
        "89",
        0
      ],
      "vae": [
        "256",
        0
      ],
      "audio_encoder_output_1": [
        "170",
        0
      ],
      "start_image": [
        "259",
        0
      ],
      "width": [
        "255",
        0
      ],
      "height": [
        "254",
        0
      ],
      "length": [
        "173",
        1
      ],
      "video_fps": 20.000000000000004,
      "motion_frame": 9,
      "audio_scale": 1.0000000000000002
    }
  },
  "239": {
    "class_type": "GetNode",
    "inputs": {}
  },
  "90": {
    "class_type": "VAELoader",
    "inputs": {
      "vae_name": "wan_2.1_vae.safetensors"
    }
  },
  "93": {
    "class_type": "CLIPTextEncode",
    "inputs": {
      "clip": [
        "251",
        0
      ],
      "text": [
        "236",
        0
      ]
    }
  },
  "89": {
    "class_type": "CLIPTextEncode",
    "inputs": {
      "clip": [
        "251",
        0
      ],
      "text": "Vivid tones, overexposed, static, blurred details, subtitles, style, artwork, painting, frame, static, overall grayness, worst quality, low quality, JPEG compression artifacts, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, misshapen limbs, fused fingers, motionless frames, cluttered backgrounds, three legs, crowded backgrounds, walking backwards"
    }
  },
  "230": {
    "class_type": "SetNode",
    "inputs": {
      "INT": [
        "216",
        0
      ]
    }
  },
  "190": {
    "class_type": "PreviewAny",
    "inputs": {
      "source": [
        "173",
        1
      ]
    }
  },
  "246": {
    "class_type": "GetNode",
    "inputs": {}
  },
  "95": {
    "class_type": "UNETLoader",
    "inputs": {
      "unet_name": "wan2.2_i2v_high_noise_14B_fp8_scaled.safetensors",
      "weight_dtype": "fp8_e4m3fn_fast"
    }
  },
  "96": {
    "class_type": "UNETLoader",
    "inputs": {
      "unet_name": "wan2.2_i2v_low_noise_14B_fp8_scaled.safetensors",
      "weight_dtype": "fp8_e4m3fn_fast"
    }
  },
  "186": {
    "class_type": "KSamplerAdvanced",
    "inputs": {
      "model": [
        "192",
        0
      ],
      "positive": [
        "192",
        2
      ],
      "negative": [
        "192",
        3
      ],
      "latent_image": [
        "192",
        4
      ],
      "add_noise": "enable",
      "noise_seed": 383944716215365,
      "steps": 4,
      "cfg": 1,
      "sampler_name": "euler",
      "scheduler": "simple",
      "start_at_step": 0,
      "end_at_step": 2,
      "return_with_leftover_noise": "disable"
    }
  },
  "187": {
    "class_type": "KSamplerAdvanced",
    "inputs": {
      "model": [
        "192",
        1
      ],
      "positive": [
        "192",
        2
      ],
      "negative": [
        "192",
        3
      ],
      "latent_image": [
        "186",
        0
      ],
      "add_noise": "enable",
      "noise_seed": 955485740784834,
      "steps": 4,
      "cfg": 1,
      "sampler_name": "euler",
      "scheduler": "simple",
      "start_at_step": 2,
      "end_at_step": 10000,
      "return_with_leftover_noise": "disable"
    }
  },
  "168": {
    "class_type": "LoadAudio",
    "inputs": {
      "audio": "e36247d1888a9e406677aba2919f260e2195a969a04bfa77c2f5af317193c030.WAV"
    }
  },
  "173": {
    "class_type": "PainterAudioCut",
    "inputs": {
      "audio": [
        "239",
        0
      ],
      "end_frame": [
        "246",
        0
      ],
      "frame_rate": 20,
      "start_frame": -4,
      "tail_silence_frames": 22
    }
  },
  "264": {
    "class_type": "MelBandRoFormerSampler",
    "inputs": {
      "model": [
        "263",
        0
      ],
      "audio": [
        "173",
        0
      ]
    }
  },
  "263": {
    "class_type": "MelBandRoFormerModelLoader",
    "inputs": {
      "model_name": "MelBandRoFormer_comfy/MelBandRoformer_fp16.safetensors"
    }
  },
  "169": {
    "class_type": "AudioEncoderLoader",
    "inputs": {
      "audio_encoder_name": "wav2vec2-chinese-base_fp16.safetensors"
    }
  },
  "195": {
    "class_type": "LayerUtility: ImageScaleByAspectRatio V2",
    "inputs": {
      "image": [
        "237",
        0
      ],
      "scale_to_length": [
        "238",
        0
      ],
      "aspect_ratio": "original",
      "proportional_width": 1,
      "proportional_height": 1,
      "fit": "crop",
      "method": "lanczos",
      "round_to_multiple": "16",
      "scale_to_side": "longest",
      "background_color": "#000000"
    }
  },
  "215": {
    "class_type": "CR Prompt Text",
    "inputs": {
      "prompt": "The video is 9 seconds long.Keep the scene unchanged, The woman performs the corresponding actions at the following time points:\n0-3 seconds: The woman looked at the man, then cupped his face in both hands.\n3-6 seconds: The woman made a heart shape with her hands in front of her chest.\n6-9 seconds: The woman propped her chin up with one hand.\n"
    }
  },
  "147": {
    "class_type": "VAEDecode",
    "inputs": {
      "samples": [
        "187",
        0
      ],
      "vae": [
        "257",
        0
      ]
    }
  },
  "266": {
    "class_type": "LayerUtility: PurgeVRAM V2",
    "inputs": {
      "anything": [
        "147",
        0
      ],
      "purge_cache": true,
      "purge_models": true
    }
  },
  "267": {
    "class_type": "LayerUtility: PurgeVRAM V2",
    "inputs": {
      "anything": [
        "170",
        0
      ],
      "purge_cache": true,
      "purge_models": true
    }
  },
  "170": {
    "class_type": "AudioEncoderEncode",
    "inputs": {
      "audio_encoder": [
        "169",
        0
      ],
      "audio": [
        "264",
        0
      ]
    }
  },
  "206": {
    "class_type": "JWInteger",
    "inputs": {
      "value": 205
    }
  },
  "205": {
    "class_type": "MathExpression|pysssss",
    "inputs": {
      "a": [
        "204",
        3
      ],
      "expression": "a-10"
    }
  },
  "224": {
    "class_type": "AudioCrop",
    "inputs": {
      "audio": [
        "168",
        0
      ],
      "start_time": "0:00",
      "end_time": "0:08"
    }
  },
  "189": {
    "class_type": "ColorMatch",
    "inputs": {
      "image_ref": [
        "242",
        0
      ],
      "image_target": [
        "188",
        0
      ],
      "method": "mkl",
      "strength": 1,
      "multithread": true
    }
  },
  "216": {
    "class_type": "JWInteger",
    "inputs": {
      "value": 1024
    }
  },
  "243": {
    "class_type": "GetNode",
    "inputs": {}
  },
  "197": {
    "class_type": "VHS_VideoCombine",
    "inputs": {
      "images": [
        "243",
        0
      ],
      "audio": [
        "227",
        0
      ]
    }
  }
}